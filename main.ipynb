{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read datasets\n",
    "df_credits = pd.read_csv(\"archive/tmdb_5000_credits.csv\")\n",
    "df_movies = pd.read_csv(\"archive/tmdb_5000_movies.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the datasets and check for first five rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_credits.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the general structure of both the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the shape of the first dataset\n",
    "df_credits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the shape of the second dataset\n",
    "df_movies.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**df_credits has 4803 rows and 4 columns while df_mov has 4803 rows and 20 columns. Let's explore further**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for the duplicates in the first dataset\n",
    "sum(df_credits.duplicated())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for the duplicates in the second dataset\n",
    "sum(df_movies.duplicated())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Both the datasets do not have any duplicate rows**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "checking data type of datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for the datatypes of each variable in the first dataset\n",
    "df_credits.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for the datatypes of each variable in the second dataset\n",
    "df_movies.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`release_date` variable should be of the form datetime "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for unique values in each variable in the first dataset\n",
    "df_credits.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**While there are 4803 movies in total, there are only 4800 unique titles which suggest the presence of duplicates**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for unique values in each variable in the second dataset\n",
    "df_movies.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. While there are 4803 movies in total, there are only 4800 unique titles and which suggest the presence of duplicates\n",
    "2. There are 4800 titles but 4801 original titles which suggests further investigation in the 2 variables\n",
    "3. There are 4802 unique popularity values instead of 4803 which suggests presence of duplicates\n",
    "4. Status has only 3 unique values which needs further investigation to find if we need all the observations or some of them can be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for detailed info in the first dataset\n",
    "df_credits.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for detailed info in the second dataset\n",
    "df_movies.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Presence of null values can be seen in some variables namely - `homepage`, `overview`, `release_date`, `runtime`, and `tagline`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies.status.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**It can be seen that there are almost all the obseravtions which belong to `Released` status. Therefore, we need to limit the dataset to this value of status only as including other status types also makes no sense**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**There are huge number of null counts in `homepage` followed by `tagline`. These are the variables which we might not even require in our further analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### As we saw above `original_title` and `title` unique values did not match, so we need to explore them further\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the instances where original title do not match with title column\n",
    "df_movies[['original_title', 'title']].query('original_title != title')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging df_movies and df_credits (adding 'movie_id' and 'cast' columns to df_movies)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_movies, df_credits[['movie_id', 'cast']]], axis=1)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the 'profitable' column\n",
    "df['profitable'] = df.revenue > df.budget\n",
    "df['profitable'] = df['profitable'].astype(int)\n",
    "\n",
    "# Defining the Outcomes\n",
    "regression_target = 'revenue'\n",
    "classification_target = 'profitable'\n",
    "\n",
    "df[\"profitable\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**So, we saw that there are 261 instances where `original_title` doesn't match with `title`. So, it's possible that number of unique values differ in both the columns. Therefore, we are on the same place as before that we need to explore `title` column further which we will do in the _Further Exploration and Cleaning_ section**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Exploration and Cleaning \n",
    "\n",
    "#### Issues to be resolved:\n",
    "1. Filter df_movies to the observations with Released status in the new dataset cl_mov which is always a good decision because we might need the original dataset at any time in the analysis\n",
    "\n",
    "2. Drop the unnecessary columns\n",
    "\n",
    "3. Drop the null observations in any variable\n",
    "\n",
    "4. Explore and check title variable further for duplicates in df_movies\n",
    "\n",
    "5. change the data type of the `release_date` to datetime in df_movies\n",
    "\n",
    "6. Try to resolve the variables that find difficult to explore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Filter df_mov to the observations with _Released_ status in the new dataset cl_mov which is always a good decision because we might need the original dataset at any time in the analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter df_movies with status 'Released'\n",
    "cl_mov = df_movies[df_movies['status'] == \"Released\"]\n",
    "cl_mov.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm only status is \"Released\"\n",
    "cl_mov.status.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Drop the unnecessary columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns not required further for analysis\n",
    "cl_mov.drop(['homepage', 'keywords', 'original_language', 'original_title', 'tagline', 'overview', 'spoken_languages', 'status'], axis=1, inplace = True)\n",
    "cl_mov.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the shape again of cl_mov\n",
    "cl_mov.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the null counts again of cl_mov\n",
    "cl_mov.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Now, cl_mov looks much better and the null counts are so less that we can directly drop the null observations in any variable**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_mov.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the shape again of cl_mov\n",
    "cl_mov.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. As we saw in the previous section, the `title` may have duplicates. So, check if there are any duplicates with respect to `title` variable**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates in the title variable in cl_mov\n",
    "cl_mov[cl_mov['title'].duplicated() == True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Check for individual duplicate titles**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_mov[cl_mov['title'].str.contains('Out of the Blue')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_mov[cl_mov['title'].str.contains('The Host')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_mov[cl_mov['title'].str.contains('Batman')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**So, we observed that our intuition was wrong and there can be two or more movies with the same name**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Change the data type of the `release_date` to datetime**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_mov['release_date'] = pd.to_datetime(cl_mov['release_date'])\n",
    "cl_mov.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning df dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the unimportant columns to reduce the amount of np.nan values in the dataset\n",
    "df.drop(['homepage', 'production_companies', 'production_countries', 'spoken_languages', 'original_title'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the number of values for which \"Revenue\" column contains \"0\"\n",
    "df[df['revenue'] == 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing the data points with \"Budget\" as \"0\" to \"np.nan\" and then checking the amount of null values present\n",
    "df['budget'] = pd.to_numeric(df['budget'], errors='coerce')\n",
    "df['budget'] = df['budget'].replace(0, np.nan)\n",
    "df[df['budget'].isnull()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a column which shows the return gained or lost from the movie production and checking the amount of null values  \n",
    "df['return'] = df['revenue'] / df['budget']\n",
    "df[df['return'].isnull()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing any infinite values with np.nan and then dropping all rows of data containing missing values\n",
    "df = df.replace([np.inf, -np.inf], np.nan)\n",
    "df.dropna(how=\"any\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the final dimensions of the dataset\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding of Genres Column\n",
    "\n",
    "Many of the variables in our dataframe contain the names of genre, actors/actresses, and keywords. Here, we add indicator columns for each genre.\n",
    "\n",
    "#### Steps\n",
    "\n",
    "- We determine all the genres in the genre column and make use of the `strip()` function on each genre to remove trailing characters.\n",
    "- Next, we include each listed genre as a new column in the dataframe. Each element of these genre columns is 1 if the movie belongs to that particular genre, and 0 otherwise, keeping in mind, a movie may belong to several genres at once.\n",
    "- This process is also called as `One-Hot Encoding` but here it is applied on each data of each row of the Column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determining and Storing the Genres\n",
    "list_genres = df.genres.apply(lambda x: x.split(\",\"))\n",
    "\n",
    "genres = []\n",
    "\n",
    "for row in list_genres:\n",
    "    row = [genre.strip() for genre in row]\n",
    "    for genre in row:\n",
    "        if genre not in genres:\n",
    "            genres.append(genre)\n",
    "\n",
    "# Encoding the Genres\n",
    "for genre in genres:\n",
    "    escaped_genre = re.escape(genre)\n",
    "    df[genre] = df['genres'].str.contains(escaped_genre).astype(int)\n",
    "\n",
    "df[genres]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the `Year` column for analysis\n",
    "\n",
    "Some variables in the dataset can be used to create new and important columns which can be further used for better analysis of the dataset\n",
    "\n",
    "#### Steps\n",
    "- Create a new column, `year` where we extract and store the year of production of a movie from the given format of `release_date`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['release_date'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year'] = pd.to_datetime(df['release_date'], errors='coerce').apply(lambda x: str(x).split('-')[0])  # if x != np.nan else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection\n",
    "\n",
    "Some variables in the dataset are already numeric and perhaps useful for regression and classification. Here, we will store the names of these variables for future use. We will also take a look at some of the continuous variables and outcomes by plotting each pair in a scatter plot. Finally, we will evaluate the skew of each variable.\n",
    "\n",
    "#### Steps \n",
    "* We call `plt.show()` to observe the plot shown below to find which of the covariates and/or outcomes are correlated with each other.\n",
    "* We call `skew()` on the columns `outcomes_and_continuous_covariates` in the dataset and check the features for which the skew is above 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_covariates = ['budget', 'popularity', 'runtime', 'vote_count', 'vote_average']\n",
    "outcomes_and_continuous_covariates = continuous_covariates + [regression_target, classification_target]\n",
    "plotting_variables = ['budget', 'popularity', regression_target]\n",
    "\n",
    "sns.pairplot(data=df[plotting_variables], height=4)\n",
    "\n",
    "# determining the skew.\n",
    "print(df[outcomes_and_continuous_covariates].skew())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* It appears that the variables `budget`, `popularity`, `runtime`, `vote_count`, and `revenue` are all right-skewed.\n",
    "* Only `vote_average` and `profitable` are the data with negative value and all the others contain positive or right skewdness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='eda'></a>\n",
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, now, as the title suggests, we are ready for **Exploratory Data Analysis**. As we know, we need to form questions for further research and analysis, this part will help us form those questions after we explore deeper and try to look at some specific areas for research. We will do this part stepwise as we have been doing till now. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_mov.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Look at the descriptive statistics of cl_mov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the descriptive statistics of the data\n",
    "cl_mov.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_rev = cl_mov['revenue'].mean()\n",
    "mean_rev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_bud = cl_mov['budget'].mean()\n",
    "mean_bud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the values look good, but let'check if there are any zero values in `revenue` and other variable that is relatable i.e. `budget`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_mov.query('revenue == 0 or budget == 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_mov.query('revenue == 0 or budget == 0').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "replace the zero values in both the columns with their respective means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_mov.replace({'revenue': {0: mean_rev}}, inplace = True)\n",
    "cl_mov.query('revenue == 0 or budget == 0').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_mov.replace({'budget': {0: mean_bud}}, inplace = True)\n",
    "cl_mov.query('revenue == 0 or budget == 0').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's check for another variable i.e. `runtime`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_mov.query('runtime == 0').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like, here also we need to replace the zero values with the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_rt = cl_mov['runtime'].mean()\n",
    "mean_rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_mov.replace({'runtime': {0: mean_rt}}, inplace = True)\n",
    "cl_mov.query('runtime == 0').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "explore `release_date` further in terms of year, month and weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a year column using release_date\n",
    "cl_mov['year'] = cl_mov['release_date'].dt.year\n",
    "cl_mov.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a month column using release_date\n",
    "cl_mov['month'] = cl_mov['release_date'].dt.month\n",
    "cl_mov.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a weekday column using release_date\n",
    "cl_mov['day'] = cl_mov['release_date'].dt.day_name()\n",
    "cl_mov.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can get the profit values bu using `revenue` and `budget` values as\n",
    "\n",
    "<b>$revenue - budget = profit$</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_mov['profit'] = cl_mov['revenue'] - cl_mov['budget']\n",
    "cl_mov.profit.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_mov.hist(figsize = (15,12));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Most movies lie in the budget range 0 to 0.5 on a e to the power 8 scale\n",
    "2. Most movies were made in the months of January and December\n",
    "3. Most movies have popularity between 0 to 100 \n",
    "4. Many movies have negative profit values which suggests loss making movies\n",
    "5. Most movies have revenue collection in the range 0 to 0.25 but on a e to the power of 9 scale\n",
    "6. Most movies have runtime in the range of 75 to 150 \n",
    "7. Vote average has a bit scattered distribution than other variables with most movies lying in the range of 6-7 voting average\n",
    "8. Most movies have been released between the years 2000 and 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.plotting.scatter_matrix(cl_mov, figsize = (15,15));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among these scatterplots we will observe our relations of interest:\n",
    "1. Profit vs Popularity shows positive but low correlation.\n",
    "2. Profit vs Revenue shows the highest positive correlation\n",
    "3. Profit vs Runtime show positive but very low correlation\n",
    "4. Vote Average vs Runtime also show positive but low correlation\n",
    "5. Popularity vs runtime also has very low but positive correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which weekdays as release days turn out to be most lucky for movies in terms of popularity and profit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate the necessay variables and groupby weekdays \n",
    "df1 = cl_mov.groupby('day')[['profit', 'popularity']]\n",
    "df1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the mean of dependent variables\n",
    "df1 = df1.mean()\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.bar(df1.index, df1['profit'], color='b', alpha=0.5, label='Profit')\n",
    "# plt.bar(df1['popularity']*1e7, color='g', alpha=0.5, width=bar_width, label='Popularity/1e7')\n",
    "\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Amount')\n",
    "plt.title('Profit and Popularity by Day')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.bar(df1.index ,df1['popularity'], color='g', alpha=0.5, label='Popularity')\n",
    "\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Amount')\n",
    "plt.title('Profit and Popularity by Day')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Wednesday has the highest average profit i.e 108 Million Dollars for the movies released on that day.\n",
    "2. Friday has the lowest average profit i.e. 49.9 Million Dollars for the movies released on that day.\n",
    "3. Wednesday has the highest average popularity too i.e 32.69 units\n",
    "4. Sunday has the lowest average popularity i.e. 14.35 units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How the time duration has been affecting High Profits, High Voting Average and High Popularity over the years from 2000 to 2017 ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_mov.query('year >= 2000')['year'].value_counts().plot(kind='pie', figsize=(8, 8), autopct='%1.1f%%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v1 = cl_mov.query('year >= 2000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_coefficient = df_v1['runtime'].corr(df_v1['profit'])\n",
    "print(correlation_coefficient)\n",
    "\n",
    "# Assuming df_v1 is your DataFrame\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df_v1['runtime'], df_v1['profit'], alpha=0.5)\n",
    "plt.title('Profit vs. Runtime')\n",
    "plt.xlabel('Runtime')\n",
    "plt.ylabel('Profit')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From the above calculations and the overall trend, we decided the ranges**\n",
    "\n",
    "**a. 0-80 for short movies**\n",
    "\n",
    "**b. 80-140 for medium movies**\n",
    "\n",
    "**c. Greater than 140 for long movies**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Divide the dataset in 3 different subsets according to the above defined ranges for runtime**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Form a dataset for short movies\n",
    "df_v2 = df_v1.query('runtime < 80')\n",
    "\n",
    "correlation_coefficient = df_v2['runtime'].corr(df_v1['profit'])\n",
    "print(correlation_coefficient)\n",
    "\n",
    "# Assuming df_v1 is your DataFrame\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df_v2['runtime'], df_v2['profit'], alpha=0.5)\n",
    "plt.title('Profit vs. Runtime')\n",
    "plt.xlabel('Runtime')\n",
    "plt.ylabel('Profit')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Form a dataset for medium movies\n",
    "df_v3 = df_v1.query('(runtime >= 80) & (runtime <140)')\n",
    "\n",
    "correlation_coefficient = df_v3['runtime'].corr(df_v1['profit'])\n",
    "print(correlation_coefficient)\n",
    "\n",
    "# Assuming df_v1 is your DataFrame\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df_v3['runtime'], df_v3['profit'], alpha=0.5)\n",
    "plt.title('Profit vs. Runtime')\n",
    "plt.xlabel('Runtime')\n",
    "plt.ylabel('Profit')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Form a dataset for long movies\n",
    "df_v4 = df_v1.query('runtime >= 140')\n",
    "\n",
    "correlation_coefficient = df_v4['runtime'].corr(df_v1['profit'])\n",
    "print(correlation_coefficient)\n",
    "\n",
    "# Assuming df_v1 is your DataFrame\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df_v4['runtime'], df_v4['profit'], alpha=0.5)\n",
    "plt.title('Profit vs. Runtime')\n",
    "plt.xlabel('Runtime')\n",
    "plt.ylabel('Profit')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there is no correlation between runtime and profit\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "daneshkar2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
